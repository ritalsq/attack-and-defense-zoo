# attack-and-defense-zoo
## 攻击-经典
### CVPR-2017-Universal_Adversarial_Perturbations  https://arxiv.org/pdf/1610.08401v3.pdf https://github.com/LTS4/universal.
### CVPR-2016- DeepFool: a simple and accurate method to fool deep neural networks https://arxiv.org/abs/1511.04599 http://github.com/lts4/deepfool

## 防御-经典
## 攻击-会议论文
### AAAI-2019-Distributionally Adversarial Attack https://arxiv.org/abs/1808.05537v3 https://github.com/tianzheng4/Distributionally-Adversarial-Attack

### CVPR-2018-Robust Physical-World Attacks on Deep Learning Visual Classiﬁcation https://arxiv.org/abs/1707.08945v5 
### ICCV_2017_Xie_Adversarial_Examples_for_for Semantic Segmentation and Object Detection(数据随机化方法) https://arxiv.org/abs/1703.08603
### ICIR-2018-DECISION-BASED ADVERSARIAL ATTACKS RELIABLE ATTACKS AGAINST BLACK-BOX MACHINE LEARNING MODELS https://arxiv.org/abs/1712.04248v1 https://github.com/bethgelab/foolbox
### ICLR-2016-ADVERSARIAL MANIPULATION OF DEEP REPRESENTATIONS https://arxiv.org/abs/1511.05122v9 

## 防御-会议论文
